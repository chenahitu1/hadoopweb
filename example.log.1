DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: 86130
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: 86130" with name 86130
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "86130"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:86130 (auth:SIMPLE)
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 89ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #1
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 9ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #2
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #2
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 1ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #3
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #3
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 2ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - /abcd.txt: masked=rw-r--r--
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #4
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #4
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 27ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/abcd.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
DEBUG LeaseRenewer:root@192.168.72.132:9000 org.apache.hadoop.hdfs.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_732620484_1] with renew id 1 started
DEBUG main org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/abcd.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
DEBUG main org.apache.hadoop.hdfs.DFSClient - Queued packet 0
DEBUG main org.apache.hadoop.hdfs.DFSClient - Queued packet 1
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Allocating new block
DEBUG main org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #5
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #5
DEBUG Thread-3 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 22ms
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - pipeline = DatanodeInfoWithStorage[192.168.72.132:50010,DS-a54ea63d-43a7-44f5-987d-b7f3eba4dbc2,DISK]
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode hadoopcentos:50010
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Send buf size 131072
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #6
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #6
DEBUG Thread-3 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 13ms
DEBUG Thread-3 org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = hadoopcentos/192.168.72.132, datanodeId = DatanodeInfoWithStorage[192.168.72.132:50010,DS-a54ea63d-43a7-44f5-987d-b7f3eba4dbc2,DISK]
DEBUG DataStreamer for file /abcd.txt block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 8
DEBUG ResponseProcessor for block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DEBUG DataStreamer for file /abcd.txt block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 sending packet packet seqno: 1 offsetInBlock: 8 lastPacketInBlock: true lastByteOffsetInBlock: 8
DEBUG ResponseProcessor for block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DEBUG DataStreamer for file /abcd.txt block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024 org.apache.hadoop.hdfs.DFSClient - Closing old block BP-1306894302-127.0.0.1-1638890338160:blk_1073741846_1024
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #7
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #7
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 4ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #8
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #8
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 3ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@29626d54
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@76508ed1
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /atubo: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (1773638882) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (1773638882) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (1773638882) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (1773638882) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (1773638882) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 232ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@76508ed1
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@76508ed1
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@76508ed1
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (1773638882) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (1773638882) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (1773638882) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (1773638882) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: delete took 139ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getListing took 103ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /atubo: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 98ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /picture: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 78ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /music: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 81ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.hdfs.DFSClient - /document: masked=rwxr-xr-x
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 77ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@34b7ac2f
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: 86130
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: 86130" with name 86130
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "86130"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:86130 (auth:SIMPLE)
DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
DEBUG main org.apache.hadoop.ipc.Client - Connecting to /192.168.72.132:9000
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: starting, having connections 1
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #0
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #0
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 85ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #1
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #1
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 2ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #2
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #2
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 2ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - /picture/js.jpg: masked=rw-r--r--
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #3
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #3
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 18ms
DEBUG main org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/picture/js.jpg, chunkSize=516, chunksPerPacket=126, packetSize=65016
DEBUG LeaseRenewer:root@192.168.72.132:9000 org.apache.hadoop.hdfs.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-143053186_1] with renew id 1 started
DEBUG main org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/picture/js.jpg, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
DEBUG main org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk packet full seqno=0, src=/picture/js.jpg, bytesCurBlock=64512, blockSize=134217728, appendChunk=false
DEBUG main org.apache.hadoop.hdfs.DFSClient - Queued packet 0
DEBUG main org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/picture/js.jpg, chunkSize=516, chunksPerPacket=126, packetSize=65016
DEBUG main org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=1, src=/picture/js.jpg, packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Allocating new block
DEBUG main org.apache.hadoop.hdfs.DFSClient - Queued packet 1
DEBUG main org.apache.hadoop.hdfs.DFSClient - Queued packet 2
DEBUG main org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: 2
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #4
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #4
DEBUG Thread-3 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 49ms
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - pipeline = DatanodeInfoWithStorage[192.168.72.132:50010,DS-a54ea63d-43a7-44f5-987d-b7f3eba4dbc2,DISK]
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Connecting to datanode hadoopcentos:50010
DEBUG Thread-3 org.apache.hadoop.hdfs.DFSClient - Send buf size 131072
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #5
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #5
DEBUG Thread-3 org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 18ms
DEBUG Thread-3 org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = hadoopcentos/192.168.72.132, datanodeId = DatanodeInfoWithStorage[192.168.72.132:50010,DS-a54ea63d-43a7-44f5-987d-b7f3eba4dbc2,DISK]
DEBUG DataStreamer for file /picture/js.jpg block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
DEBUG DataStreamer for file /picture/js.jpg block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 sending packet packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 110856
DEBUG ResponseProcessor for block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DEBUG ResponseProcessor for block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DEBUG DataStreamer for file /picture/js.jpg block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 sending packet packet seqno: 2 offsetInBlock: 110856 lastPacketInBlock: true lastByteOffsetInBlock: 110856
DEBUG ResponseProcessor for block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
DEBUG DataStreamer for file /picture/js.jpg block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026 org.apache.hadoop.hdfs.DFSClient - Closing old block BP-1306894302-127.0.0.1-1638890338160:blk_1073741848_1026
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #6
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #6
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 18ms
DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root sending #7
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root got value #7
DEBUG main org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 4ms
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3d74bf60
DEBUG Thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: closed
DEBUG IPC Client (252651381) connection to /192.168.72.132:9000 from root org.apache.hadoop.ipc.Client - IPC Client (252651381) connection to /192.168.72.132:9000 from root: stopped, remaining connections 0
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
DEBUG main org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:root (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:303)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:328)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
ERROR main org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:356)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:371)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:364)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2807)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:2802)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2668)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:371)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:160)
	at org.apache.hadoop.fs.FileSystem$1.run(FileSystem.java:157)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:157)
	at com.cht.hadoopDemo.HadoopTest.<init>(HadoopTest.java:23)
	at com.cht.hadoopDemo.HadoopTest.main(HadoopTest.java:128)
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=C:\Program Files\Java\jdk1.8.0_241\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\VMware Workstation\bin\;C:\Program Files\ImageMagick-7.1.0-Q16-HDRI;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64_win\compiler;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Users\86130\AppData\Local\Google\Chrome\Application;C:\Program Files\MySQL\MySQL Server 5.7\bin;D:\Download\pdi-ce-7.1.0.0-12\data-integration;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\Program Files\;C:\Program Files\Git\cmd;C:\Program Files (x86)\ZeroTier\One\;C:\Users\86130\Downloads\potrace-1.16.win64;C:\Users\86130\Downloads\pngquant;C:\Users\86130\Downloads\pngnq-0.5-i386-win;D:\maven\apache-maven-3.6.3\apache-maven-3.6.3\bin;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\Scripts\;C:\Users\86130\AppData\Local\Programs\Python\Python38-32\;C:\Users\86130\AppData\Local\Microsoft\WindowsApps;C:\Program Files\Java\jdk1.8.0_241\bin;C:\Program Files\Java\jdk1.8.0_241\jre\bin;C:\Program Files\Bandizip\;D:\Program Files\PyCharm 2020.1.1\bin;;C:\Program Files\JetBrains\PyCharm Community Edition 2020.3.1\bin;;D:\Program Files\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3\bin;;C:\Users\86130\AppData\Local\GitHubDesktop\bin;.
